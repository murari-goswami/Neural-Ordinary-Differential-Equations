{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_ODE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "mngX1UO4YeL6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Ordinary Differential Equations\n",
        "\n",
        "##Summary\n",
        "\n",
        "\n",
        "NeurIPS (Neural Information Processing System) is the largest AI conference in the world. About 4,854 papers were submitted (NeurIPS 2018) out of which 4 received the \"Best paper\" award. This is one of them. The basic idea is that neural networks are made up of stacked layers of simple computation nodes that work together to approximate a function. If we re-frame a neural network as an \"Ordinary Differential Equation\", we can use existing ODE solvers (like Euler's method) to approximate a function. This means no discrete layers, instead the network is a continous function and the result is that, there would be no need to mention the number of layers beforehand, we can mention the accuracy and the ODEnet would approximmate the whole network to that error margin. It's still early stages, but this could be as big a breakthrough as GANs!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VkOKTYj_lJBC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Why is this important?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.  Faster testing time than recurrent networks, but slower training time., consumes less memory\n",
        "2.  More accurate results for time series predictions  i.e continous-time models\n",
        "Opens up a whole new realm for optimizing neural networks (Diff Equation Solvers)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rMZwuzKSuogq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Differential Equations\n",
        "\n",
        "\n",
        "A differential equation is a mathematical equation that relates some function with its derivatives. In applications, the functions usually represent physical quantities, the derivatives represent their rates of change, and the equation defines a relationship between the two\n",
        "\n",
        "![alt text](data:image/png;base64,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)\n",
        "\n",
        "**\"_Fig Above:- A simple Differential Equation_\"**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/153e0361b86ebf7612d4f0f667736d4cbe005568/687474703a2f2f6879706572706879736963732e7068792d617374722e6773752e6564752f68626173652f4d6174682f696d6d6174682f646572696e742e676966)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ######            ![alt text](https://revisionworld.com/sites/revisionworld.com/files/imce/differential.gif)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IZ7FZAgR3ehy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Code For Differential Equation"
      ]
    },
    {
      "metadata": {
        "id": "F9dRKnd_prvt",
        "colab_type": "code",
        "outputId": "a29d8c52-785d-4cec-84cd-6e12a80be590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# function dy/dx = x + y/5.\n",
        "func = lambda y,x : x + y/5.\n",
        "# Initial condition\n",
        "y0 = -3  # at x=0\n",
        "# values at which to compute the solution (needs to start at x=0)\n",
        "x = np.linspace(0, 4, 101)\n",
        "# solution\n",
        "y = odeint(func, y0, x)\n",
        "# plot the solution, note that y is a column vector\n",
        "plt.plot(x, y[:,0])\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIBNENoAANgEoQ0AgE0Q2gAA2MT/BxLE0LUjCQqWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CDLcHaul3WdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Ordinary Differential Equation\n",
        "\n",
        "\n",
        "Consider a simplified ODE from physics: we want to model the position x of a car. Assume we can calculate its velocity x′ (the derivative of position) at any position x. We know that the car starts at rest x(0)=0 and that its velocity at time t depends on its position through the formula:\n",
        "\n",
        "$$ x^\\prime(t) = f(x) $$\n",
        "The Euler method solves this problem by following the physical intuition: my position at a time very close to the present depends on my current velocity and position. For example, if you are travelling at a velocity of 5 meters per second, and you travel 1 second, your position changes by 5 meters. If we travel h seconds, we will have travelled 5h meters. As a formula, we said:\n",
        "\n",
        "$$x(t+h) = x(t) + h x^\\prime(t),$$\n",
        "but since we know\n",
        "\n",
        "$$ x^\\prime(t) = f(x) $$\n",
        "\n",
        "we can rewrite this as..equation (1). Remember the equation below\n",
        "\n",
        "$$ x(t+h) = x(t) + h f(x).$$    \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tYr-pNJelWnl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##ResNet(2015)\n",
        "\n",
        "\n",
        "\n",
        "Imagine a deep CNN architecture. Take that, double the number of layers, add a couple more, and it still probably isn’t as deep as the ResNet architecture that Microsoft Research Asia came up with in late 2015. ResNet is a new 152 layer network architecture that set new records in classification, detection, and localization through one incredible architecture. Aside from the new record in terms of number of layers, ResNet won ILSVRC 2015 with an incredible error rate of 3.6%\n",
        "\n",
        "![alt text](https://adeshpande3.github.io/assets/ResNet.gif)\n",
        "\n",
        "\n",
        "\n",
        "##Residual Block\n",
        "\n",
        "The idea behind a residual block is that you have your input x go through conv-relu-conv series.This will give you some F(x).That result is then added to the original input x. Let’s call that H(x) = F(x) + x.In traditional CNNs, your H(x) would just be equal to F(x) right? So, instead of just computing that transformation (straight from x to F(x)), we’re computing the term that you have to add, F(x), to your input, x. Basically, the mini module shown below is computing a “delta” or a slight change to the original input x to get a slightly altered representation (When we think of traditional CNNs, we go from x to F(x) which is a completely new representation that doesn’t keep any information about the original x). \n",
        "\n",
        "\n",
        "# # ![alt text](https://adeshpande3.github.io/assets/ResNet.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The residual layer is actually quite simple: add the output of the activation function to the original input to the layer. As a formula, the k+1th layer has the formula:\n",
        "\n",
        "$$ x_{k+1} = x_{k} + F(x_{k})$$\n",
        "where F is the function of the kth layer and its activation. For example, F might represent a convolutional layer with a relu activation. This simple formula is a special case of the formula:\n",
        "\n",
        "(Equation 2)\n",
        "\n",
        "$$ x_{k+1} = x_{k} + h F(x_k),$$\n",
        "\n",
        "\n",
        "\n",
        "Now you can see that equation (1) and equation (2) are the same.\n",
        "\n",
        "you can see it looks just like the formula for ODE !"
      ]
    },
    {
      "metadata": {
        "id": "HG5p1FfLpBT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This observation has meant three things for designing neural networks:\n",
        "\n",
        "\n",
        "\n",
        "1.   New neural network layers can be created through different numerical approaches to solving ODEs\n",
        "2.   The possibility of arbitrarily deep neural networks\n",
        "\n",
        "3.   Gradient descent can be viewed as applying Euler's method for solving ordinary differential  equation to gradient flow.\n",
        "\n",
        "#![alt text](//camo.githubusercontent.com/a1da3a451fe610f93151dd9065f623778ac5442e/68747470733a2f2f77696b696d656469612e6f72672f6170692f726573745f76312f6d656469612f6d6174682f72656e6465722f7376672f66376566643234653963663334353038646638643430326135623938303132393061636232616663)\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IXYKybc5XF50",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#ODENet\n",
        "\n",
        "\n",
        "##Neural networks as differential equations\n",
        "\n",
        "Consider a multi-layered neural network. We have an input layer and an output layer, and inbetween them, some number of hidden layers. As an input feeds forward through the network, it is progressively transformed, one layer at a time, from the input to the ultimate output. Each network layer is a step on that journey. If we take a small number of big steps, we end up with a rough approximation to the true transformation function we’d like to learn. If we take a much larger number of steps (deeper networks), with each step being individually smaller, we have a more accurate approximation to the true function. What happens in the limit as we take an infinite number of infinitely small steps?\n",
        "\n",
        "So one way of thinking about those hidden layers is as steps in Euler’s method for solving differential equations\n",
        "\n",
        "#![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Euler_method.svg/412px-Euler_method.svg.png)\n",
        "\n",
        "\n",
        "\n",
        "We want to recover the blue curve, but all we have is an initial point A0 (think inputs to the network) and a differential equation. From the differential equation, we can calculate the tangent line. If we take a small step along the tangent line, we arrive at A1, which will be close to the desired blue line if the step is small enough. Repeat this process to uncover a polygonal curve A0,A1,A2..An\n",
        "\n",
        "\n",
        "\n",
        "##What Does an ODENet Look like?\n",
        "\n",
        "####*An ODE is a function that usually describes the change of some system through time. In this setting, time is a continuous variable. Now imagine a neural network is that system, and time is really something more like the depth of the network. It has a continuous number of layers*\n",
        "\n",
        "\n",
        "*   \n",
        "The team although didn't use Euler's method, they computed the exact ODE solution (within a small error tolerance) using adaptive solvers (which is faster).\n",
        "*   \n",
        "The dynamics change smoothly with depth. You can think of this either as having weights that are\n",
        "a  function of depth, or as having shared weights across layers but adding the depth as an extra input to f.  Anywhere you can put a resnet you can put an ODEnet\n",
        "* Each ODEBlock can be used to replace a whole stack of ResBlocks.\n",
        "* In their MNIST example, each ODEBlock replaces 6 ResBlocks.\n",
        "\n",
        "###Traditional Deep Nets\n",
        "\n",
        "h1 = f1(x)\n",
        "\n",
        "h2 = f2(h1)\n",
        "\n",
        "h3 = f3(h2)\n",
        "\n",
        "h4 = f3(h3)\n",
        "\n",
        "y  = f5(h4)\n",
        "\n",
        "###ResNets\n",
        "\n",
        "h1 = f1(x)  + x\n",
        "\n",
        "h2 = f2(h1) + h1\n",
        "\n",
        "h3 = f3(h2) + h2\n",
        "\n",
        "h4 = f4(h3) + h3\n",
        "\n",
        "y  = f5(h4) + h4\n",
        "\n",
        "\n",
        "Where f1, f2, etc are neural net layers.\n",
        "The idea is that it's easier to model a small change to an almost-correct answer than to output the whole improved answer at once. -The above looks like a primitive ODE solver (Euler's method) that solves the trajectory of a system by just taking small steps in the direction of the dynamics of the and adding them up. -They connection allows for better training methods.\n",
        "What if we define a deep net as a continuously evolving system?\n",
        "Instead of updating the hidden units layer by layer, we define their derivative with respect to depth instead.\n",
        "\n",
        "Many neural networks have a composition that looks exactly like the steps of Euler’s method. We start with an initial state z0, and apply successive transformations over time (layers):\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "C4wmsjh6uIQp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$ z1 = z0 +  f(z0,\\theta0).$$   \n",
        "$$ z2 = z1 +  f(z1,\\theta1).$$   \n",
        "$$ z3 = z2 +  f(z2,\\theta2).$$...   and so on\n",
        "\n",
        "\n",
        "In the limit, we parameterize the continuous dynamics of hidden units using an ordinary differential equation (ODE) specified by a neural network:\n",
        "\n",
        "![alt text](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7Bd%5Cmathbf%7Bz%7D%28t%29%7D%7Bdt%7D+%3D+f%28%5Cmathbf%7Bz%7D%28t%29%2C+t%2C+%5Ctheta%29&bg=ffffff&fg=333333&s=0&zoom=1)\n",
        "\n",
        "\n",
        "The equivalent of having T layers in the network, is finding the solution to this ODE at time T.\n",
        "\n",
        "\n",
        "![alt text](https://adriancolyer.files.wordpress.com/2019/01/NODEs-Fig-1.jpeg?w=480&zoom)\n",
        "\n",
        "\n",
        "\n",
        "Euler’s method is perhaps the simplest method for solving ODEs. There since been more than 120 years of development of efficient and accurate ODE solvers. Modern ODE solvers provide guarantees about the growth of approximation error, monitor the level of error, and adapt their evaluation strategy on the fly to achieve the requested level of accuracy. This allows the cost of evaluating a model to scale with problem complexity.\n",
        "\n",
        "\n",
        "\n",
        "##How to train a continuous-depth network ?\n",
        "\n",
        "Question is how do you efficiently train a network defined as a differential equation? The answer lies in the adjoint method (which dates back to 1962). Think of the adjoint as the instantaneous analog of the chain rule.\n",
        "\n",
        "This approach computes gradients by solving a second, augmented ODE backwards in time, and is applicable to all ODE solvers. This approach scales linearly with problem size, has low memory cost, and explicitly controls numerical error.\n",
        "\n",
        "\n",
        "The adjoint captures how the loss function L changes with respect to the hidden state\n",
        "\n",
        "![alt text](https://s0.wp.com/latex.php?latex=-+%5Cpartial+L+%2F+%5Cpartial+%5Cmathbf%7Bz%7D%28t%29&bg=ffffff&fg=333333&s=0&zoom=1)\n",
        "\n",
        "Starting from the Output network, we can recompute $z({t})$ backwards in time together with the adjoint.\n",
        "\n",
        "\n",
        "![alt text](https://adriancolyer.files.wordpress.com/2019/01/NODEs-Fig-2.jpeg?w=480&)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kPDpU9sWVf5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A third integral then tells us how the loss changes with the parameters\n",
        "###$$ \\theta( dL/d\\theta).$$\n",
        "\n",
        "All three of these integrals can be computed in a single call to an ODE solver, which concatenates the original state, the adjoint, and the other partial derivatives into a single vector. Algorithm 1 shows how to construct the necessary dynamics, and call an ODE solver to compute all gradients at once. That is all I can possibly manage to explain at this point.\n",
        "\n",
        "\n",
        "###![alt text](https://adriancolyer.files.wordpress.com/2019/01/NODEs-Alg-1.jpeg?w=556&zoom=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Applied Neural ODEs\n",
        "\n",
        "###Residual Networks\n",
        "\n",
        "This section tackles the good old MNIST problem, comparing an ODE-net to a ResNet with 6 residual blocks. The ODE-net replaces the residual blocks with an ODE-Solve module.\n",
        "\n",
        "Concentrating on the **2nd and 4th lines** in the table below, ODE-Nets are able to achieve roughly the same performance as a ResNet, but using only about 1/3 of the parameters. Also note that the ODE-Net solution using constant memory, whereas ResNets use memory proportional to the number of layers.\n",
        "\n",
        "\n",
        "##![alt text](https://adriancolyer.files.wordpress.com/2019/01/NODEs-Table-1.jpeg?w=540&zoom=1)"
      ]
    },
    {
      "metadata": {
        "id": "M7b6gqRLYN3X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Time-series\n",
        "This is the application which  caught my attention.\n",
        "\n",
        "Applying neural networks to irregularly-sampled data such as medical records, network traffic, or neural spiking data is difficult. Typically, observations are put into bins of fixed duration, and the latent dynamics are discretized in the same way. This leads to difficulties with missing data and ill-defined latent variables… We present a continuous-time, generative approach to modeling time series. Our model represents each time series by a latent trajectory. Each trajectory is determined from a local initial state $\\mathbf{z}_{t_0}$, and a global set of latent dynamics shared across all time series.\n",
        "\n",
        "The model can be trained as a variational autoencoder, and it looks like this:\n",
        "\n",
        "![alt text](https://adriancolyer.files.wordpress.com/2019/01/NODEs-Fig-6.jpeg?w=566&zoom=2)\n",
        "\n",
        "\n",
        "\n",
        "The evaluation here is based on a dataset of 1000 2-dimensional spirals, each starting at a different point. Half of the spirals are clockwise, and half counter-clockwise. Points are sampled from these trajectories at irregular timestamps. The figure below shows a latent neural ODE is better able to recover the spirals than a traditional RNN:\n",
        "\n",
        "![alt text](https://adriancolyer.files.wordpress.com/2019/01/NODEs-Fig-8.jpeg?w=350&zoom=1)\n",
        "\n",
        "\n",
        "Find the original repo [here](https://https://github.com/rtqichen/torchdiffeq)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###My Result:-\n",
        "\n",
        "C:\\torchdiffeq\\examples>python ode_demo.py --viz\n",
        "\n",
        "Iter 0020 | Total Loss 0.637604\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0040 | Total Loss 0.693041\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0060 | Total Loss 0.721506\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0080 | Total Loss 0.332976\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0100 | Total Loss 0.656128\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0120 | Total Loss 0.641541\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0140 | Total Loss 0.799464\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0160 | Total Loss 0.263458\n",
        "\n",
        "No handles with labels found to put in legend.\n",
        "Iter 0180 | Total Loss 0.274314\n",
        "\n",
        "![alt text](https://github.com/rtqichen/torchdiffeq/raw/master/assets/ode_demo.gif)"
      ]
    },
    {
      "metadata": {
        "id": "8sp6tdfdsgqc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Closing Summary of Neural ODE\n",
        "A neural network is a popular type of machine learning model\n",
        "Neural Networks are built with linear algebra and optimized using Calculus\n",
        "\n",
        "* Neural networks consist of a series of \"layers\", which are just matrix operations\n",
        "\n",
        "* Each layer introduces a little bit of error that compounds through the network\n",
        "* The way to reduce that error is to add more and more layers\n",
        "* The problem is that we see a drop off in performance after a certain # of layers\n",
        "* A solution to this was proposed by Microsoft for the 2015 ImageNet competiton (residual networks)\n",
        "* Residual Networks connect the output of previous layers to the output of new layers\n",
        "* Prof. Duvenaud's team at University of Toronto noticed that that ResNets are similar to a primative * * \"Ordinary Differential Equation\" Solver called \"Euler's Method\"\n",
        "* Ordinary Differential Equations involve one or more ordinary derivatives of unkown functions. 1 independent variable.\n",
        "* Partial Differential Equations involve one or more partial derivatives of unknown functions. 2 or more independnet variables.\n",
        "* Eulers method is a numerical method to sovle 1st order differential equations.\n",
        "More efficient than Eulers method is the adjoint method. And this acts as our optimization strategy\n",
        "The result? No need to specificy number of layers beforehand, now just specifiy accuracy. it will train itself.\n",
        "* No more discrete layers, instead a continous computational block\n",
        "\n",
        "\n",
        "**Applications** -Irregular time series data (medical history recorded at random times)."
      ]
    }
  ]
}